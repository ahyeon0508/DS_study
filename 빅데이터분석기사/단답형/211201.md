## 211201 단답형 공부
#### 📖 참고 : 이기적스터디카페 - 16주차 실기 단답형 예상 문제  

-----------

⭕ 다층 퍼셉트론 : XOR 연산을 표현할 수 있으며 비선형적인 결정 경계를 표현할 수 있는 단층 퍼셉트론의 한계를 뛰어넘은 개념  

⭕ ReLU : 0보다 작은 구간에서 기울기가 0이고 나머지 0보다 큰 구간에서는 항상 1의 크기의 기울기를 가지는 특성을 가지는 활성화 함수    

❌ 풀링 : 합성곱 연산을 통해 나온 결과물에서 대푯값들만 뽑아내는 과정이며 최대, 최소, 평균 등의 여러가지 기법을 가지고 있는 방법론    

⭕ RNN : 시간 순서가 있는 데이터를 잘 예측하도록 설계된 인공신경망모델 중 하나로 hidden state를 두어 과거 신호를 기억하며 반복하는 순한적 구조를 가지고 있는 신경망    

⭕ LSTM : RNN의 long term dependency를 극복하기 위해 등장한 신경망으로 cell state의 개념을 도입하여 이전 순번중 기억해야할 것을 더욱 오래 기억할 수 있게 한 모델    

❌ 전이학습 : 이미지넷과 같이 아주 큰 데이터셋에 훈련된 모델의 가중치를 가지고 와서 우리가 해결하고자 하는 과제에 맞게 재보정해서 사용하는 것을 의미하는 단어    

❌ gradient descent : 신경망 학습과정에서 weight을 조절하는 과정에서 사용하는 방법으로 loss function의 값을 최소하 하기 위해 기울기를 이용하는 방법을 의미하는 단어  

❌ SGD : batch gradient descent는 모든 학습 데이터를 가지고 연산하고 이에 따라 weight 업데이트를 진행하는 단점이 존재하는데, 이를 극복하기 위해 도입된 개념으로 전체 데이터 중 랜덤으로 데이터를 하나 뽑아 학습을 진행하는 방법    

❌ exponential decay : 신경망 모델의 학습률을 조절하는 방법중 하나로 기존 학습률에서 e^-kt를 곱하여 step이 지날수록 학습률을 줄여나가는 방법  

❌ 하드 마진 SVM : 서포트 벡터 머신의 유형중 하나로 모든 입력값이 초평면 사이의 한 클래스에는 무조건 속해야 하며, 몇 개의 이상치로 인해 초평면이 정확히 분리하지 못 하는 케이스가 존재하는 유형  

-----------

#### 📖 참고 : 이기적스터디카페 - 17주차 실기 단답형 예상 문제  

-----------

❌ FP-Growth 알고리즘 : 연관성 분석의 알고리즘의 한 종류로 FP-Tree 구조를 생성한 후 분할 정복 방식을 통해 데이터를 반복하지 않아 속도가 빠른 장점을 가진 알고리즘  

❌ 평균연결법 : 군집분석의 군집간 거리측정방법의 한 종류로 모든 항목에 대한 관측치 쌍 사이의 평균 거리를 구하는 방법    

⭕ 시그모이드 함수 : 인공신경망의 다층 퍼셉트론에서 기울기 소실의 원인에 해당하는 함수    

⭕ 패딩 : 합성곱 신경망에서 데이터의 외각에 지정된 픽셀수만큼 특정값으로 채워 넣는 방법    

❌ 하드보팅 : 보팅의 한 방법으로 분류기간의 과반수, 다수결, 만장일치 등의 조건으로 결정하는 방법론    

❌ Max_features : 랜덤포레스트 방식의 머신러닝 기법의 매개변수 중 하나로 노드 분할시 무작위로 선택되는 변수의 수를 나타내는 변수    

❌ 드롭아웃 : 딥러닝의 한 레이어에서 필터하는 방식 중 하나로 랜덤화 된 노드를 임의로 제거하여 배깅의 극단적 형태로 볼 수 있는 방법  

❌ 윌콕슨 순위합 검정 : 독립된 두집단의 중심위치를 비교하기 위한 비모수 검정방법으로 Mann-whitney의 u-statistic 검정법과 동일한 방법론    

⭕ 수정된 결정계수 : 결정계수의 일반성을 증대한 방법으로 적절하지 않은 독립변수를 추가하는 것에 대해 패널티를 부과한 결정계수이며 결정계수보다 항상 작은 값을 가지는 값  

❌ 정밀도 : TP/(TP+FP)의 수식을 통해 구하며 긍정으로 예측된 결과의 정확한 예측의 비율을 의미하는 모델의 성능 지표  

-----------